{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Investigacion\n",
    "<h1><center> Procesos de decision de Markov </center></h1>\n",
    "<h2><center> Universidad \"Politecnica Salesiana\" </center></h2>\n",
    "<h5><right>Alumno: Juan Cañar. <br> Docente: Ing. Diego Quisi. </right></h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quien fue Markov?\n",
    "\n",
    "* Fue un matematico ruso conocido por sus trabajos sobre teoria de los numeros y la teoria de probabilidades\n",
    "\n",
    "#### Definicion de busquedas de Markov.\n",
    "\n",
    "* -Serie de experimentos en que cada cada uno tiene m posibles resultados, donde dicha probabilidad depende de lo que se haya obtenido en los experimentos previos.\n",
    "\n",
    "######  **Usos de la cadena de Markov**\n",
    "\n",
    "**La aplicación se realiza en distintos ámbitos de los negocios y las finanzas, construccion de patrones para analisis en la medicina, esto permite analizar y estimar futuros patrones de conducta de los individuos**\n",
    "\n",
    "# Procesos de decision de Markov\n",
    "\n",
    "* Es un proceso de modelado matematico, caracterizado por un conjunto de estados que atraviesa a lo largo de distintos puntos de decision temporales (llamados epocas), una serie de acciones disponibles en cada estado, se les denomina sin memoria, es decir la elecion de la accion en un momento dado depende unicamente del estado actual, los estados pueden ser finito o infinito y puede considerarse horizonte.\n",
    "* **Finito** (esto significa que a partir de un instante finito, lo que significa que ya no existe transiciones entre estados ni tampoco recompensas.\n",
    "\n",
    "* **Infinito** (se define una funcion de valor con un factor de descuento sobre recompensas futuras.\n",
    "\n",
    "* Con los procesos de Markov se introducen varios elementos para la resolucion de problemas matematicos utilizando funciones de valor y las ecuaciones de Bellman.\n",
    "\n",
    "**PROPIEDAD DE MARKOV**\n",
    "\n",
    "* -El futuro es independiente del pasado, dado el presente, lo cual se expresa de la siguiente manera,    con esta formula.\n",
    "\n",
    "<img src=https://miro.medium.com/max/1400/1*stZ7ap0gsyuML7AcvJQ8hg.png width=\"300\" height=\"100\">\n",
    "\n",
    "\n",
    "**St** - Estado actual, contiene toda la informacion relevante de\n",
    "\n",
    "**S1, St** - Estados pasados\n",
    "\n",
    "## Procesos de Markov de primer orden\n",
    "\n",
    "* **Estados:** Condicones en las que se encuentra en determiando un ente o suceso posible.\n",
    "\n",
    "* **Ensayos:** Reacciones petetidas que se dan conforme se estudia un evento.\n",
    "\n",
    "* **Probabilidad de Transicion:** En un lapso de tiempo llegar a pasar de un estado actual al siguiente se representa asi:\n",
    "\n",
    "<h4><center> \"PIJ\" (Probabildad, de pasar de I a J en un periodo de tiempo) </center></h4>\n",
    "\n",
    "\n",
    "### Elementos que conforman un proceso de descripcion de Markov\n",
    "***\n",
    "- - -\n",
    "\n",
    "   * M estados: Son estados de conjunto finito, exhaustivos y mutuamente   \n",
    "    excluyentes.\n",
    "    \n",
    "   * Ciclo de markov(\"Paso\"): Periodo de tiempo que sirve de base para \n",
    "    analizar transacciones entre estados.\n",
    "    \n",
    "   * Probabilidades de transicion: **Matriz p** consiste entre estado, en un \n",
    "    ciclo.\n",
    "    \n",
    "   * Distribucion inicial: Distribuye el sistema entre los M estados posibles.   \n",
    "   - - -\n",
    "   \n",
    "### Tecnicas para resolver procesos:\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoy sera un buen Dia!! :]\n",
      "\n",
      "Dia con mucho sol\n",
      "\n",
      "Resultado de:  -7   6   -36\n"
     ]
    }
   ],
   "source": [
    "from numpy import linalg\n",
    "\n",
    "A=[[4.2,4.3,3.3],[4.2,1.3,1.4],[6.2,3.3,4.4]]\n",
    "B=[3,1,2]\n",
    "C=[[4.2,1.6,2.7],[2.2,1.3,1.4],[2.2,1.3,2.4]]\n",
    "x=[]\n",
    "\n",
    "for i in range(0,len(B)):\n",
    "    for j in range(0,len(B)):\n",
    "        C[j][i]=A[j][i]\n",
    "    x.append(int(linalg.det(C)*2))\n",
    "\n",
    "if x[0]== -7:\n",
    "    print(\"Hoy sera un buen Dia!! :]\")\n",
    "else:\n",
    "    print('')\n",
    "if x[1] ==4:\n",
    "    print(\"Llueve con rayos\")\n",
    "else:\n",
    "    print('')\n",
    "if x[2]== -36:\n",
    "    print(\"Dia con mucho sol\\n\")\n",
    "    \n",
    "print(\"Resultado de: \",x[0],\" \", x[1],\" \",x[2])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuente: \\\n",
    "[Wikipedia](https://es.wikipedia.org/wiki/Lenguaje_de_marcas_ligero) \\\n",
    "\n",
    "   \n",
    "* https://www.rcs.cic.ipn.mx/2014_74/Procesos%20de%20decision%20de%20Markov%20y%20microescenarios%20para%20navegacion%20y%20evasion%20de%20colisiones.pdf\n",
    "\n",
    "* https://core.ac.uk/download/pdf/29405478.pdf\n",
    "* \n",
    "*Ruiz, S., & Hernández, B. (2014). Procesos de decisión de Markov y microescenarios para navegación y evasión de colisiones para multitudes. Research in Computing Science, 74, 103-116.*\n",
    "* http://dinamica-de-sistemas.com/revista/0605h.htm\n",
    "\n",
    "* Paredes Pérez, O. (2016). Procesos de decisión de Markov y algunos problemas financieros (Master's thesis, Benemérita Universidad Autónoma de Puebla).\n",
    "\n",
    "* http://www.unsa.edu.ar/yazlle/public_html/discreta/08-markov.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
